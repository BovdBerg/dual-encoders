tokenizer:
  _target_: model.transformer.TransformerTokenizer
  pretrained_model: ${..pretrained_model}
  max_length: null
  add_special_tokens: False

encoder:
  _target_: model.estimator.AvgEmbQueryEstimator
  pretrained_model: ${..pretrained_model}
  n_docs: 10
  tok_embs_w_method: UNIFORM
  ckpt_path_tok_embs: /home/bovandenberg/models/emb_bert.ckpt
  embs_w_method: WEIGHTED
  q_only: False

pretrained_model: bert-base-uncased
